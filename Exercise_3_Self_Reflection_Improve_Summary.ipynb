{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968a1b82",
   "metadata": {},
   "source": [
    "# Exercise 3 — Self-Reflection Prompt for Improving Output\n",
    "This notebook shows:\n",
    "- An **original summary**\n",
    "- A **self-critique prompt** with explicit criteria\n",
    "- A revised **improved summary**\n",
    "- Clear before/after difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install openai\n",
    "\n",
    "# ===== Helper: LLM wrapper (REAL or MOCK) =====\n",
    "# This notebook runs in MOCK mode by default so you always get \"successful output\"\n",
    "# even without an API key. If you have an OpenAI key, set it and REAL mode will run.\n",
    "\n",
    "import os, json, textwrap, re, sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "MODE = os.getenv(\"LLM_MODE\", \"MOCK\").upper()  # set to REAL to use OpenAI\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "@dataclass\n",
    "class LLMResponse:\n",
    "    text: str\n",
    "\n",
    "def llm_call(system_prompt: str, user_prompt: str, mock_text: str) -> LLMResponse:\n",
    "    \"\"\"\n",
    "    Returns LLMResponse.text.\n",
    "    REAL mode uses OpenAI if OPENAI_API_KEY is set.\n",
    "    MOCK mode returns mock_text (provided per call).\n",
    "    \"\"\"\n",
    "    if MODE == \"REAL\":\n",
    "        if not OPENAI_API_KEY:\n",
    "            raise RuntimeError(\"REAL mode requested but OPENAI_API_KEY is not set.\")\n",
    "        # OpenAI SDK (recommended) — works in Colab once you `pip install openai`\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI()\n",
    "        resp = client.chat.completions.create(\n",
    "            model=os.getenv(\"OPENAI_MODEL\", \"gpt-4.1-mini\"),\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        return LLMResponse(resp.choices[0].message.content)\n",
    "    else:\n",
    "        return LLMResponse(mock_text)\n",
    "\n",
    "print(f\"✅ LLM wrapper ready. MODE={MODE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf21fc",
   "metadata": {},
   "source": [
    "## Source text to summarize (short excerpt)\n",
    "In your own assignment, paste your actual text/article excerpt here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2bc8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_text = \"\"\"\n",
    "Companies increasingly use algorithmic systems to rank, recommend, and remove content online. \n",
    "Critics argue these systems can amplify misinformation and bias while operating with limited transparency. \n",
    "Supporters claim algorithms help manage scale and personalize user experience. \n",
    "Policy proposals include transparency reports, independent audits, and user controls over recommendation settings.\n",
    "\"\"\"\n",
    "print(source_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e28ced",
   "metadata": {},
   "source": [
    "## BEFORE — initial summary (intentionally mediocre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "before_summary = \"The passage says social media uses algorithms and people have different opinions about them. Some want changes like transparency.\"\n",
    "print(before_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee455d",
   "metadata": {},
   "source": [
    "## Self-reflection / critique prompt (copy this into your write-up)\n",
    "Criteria are explicit (accuracy, coverage, clarity, audience, length, format) and it **requires a revised version**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reflect_system = \"You are a careful editor. You must critique and then revise.\"\n",
    "reflect_prompt = f\"\"\"\n",
    "You will receive (1) source text and (2) an initial summary.\n",
    "\n",
    "STEP A — CRITIQUE (bullet list):\n",
    "Check the summary against these criteria:\n",
    "- Accuracy: no invented claims; matches source.\n",
    "- Coverage: includes all key ideas (pro + con + proposed policies).\n",
    "- Clarity: specific wording; avoids vague phrases.\n",
    "- Audience: college-level, neutral tone.\n",
    "- Length: revised summary must be 55–75 words.\n",
    "- Format: Provide a revised summary in ONE paragraph.\n",
    "\n",
    "STEP B — REVISE:\n",
    "Write the improved summary that meets ALL criteria.\n",
    "\n",
    "SOURCE TEXT:\n",
    "{source_text}\n",
    "\n",
    "INITIAL SUMMARY:\n",
    "{before_summary}\n",
    "\"\"\"\n",
    "mock_reflect = \"\"\"CRITIQUE:\n",
    "- Too vague (“different opinions”), misses key details like misinformation/bias vs scale/personalization.\n",
    "- Omits policy proposals (audits, user controls).\n",
    "- Needs clearer, more specific language and target length.\n",
    "\n",
    "REVISED SUMMARY:\n",
    "The passage explains that platforms rely on algorithms to rank, recommend, and remove content at scale. Critics say these systems can amplify misinformation and embed bias while remaining opaque, whereas supporters argue they enable personalization and help manage massive volumes of posts. Proposed policy responses include stronger transparency reporting, independent audits of algorithmic impacts, and giving users more control over recommendation settings.\n",
    "\"\"\"\n",
    "reflect_out = llm_call(reflect_system, reflect_prompt, mock_reflect).text\n",
    "print(reflect_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4440f4ff",
   "metadata": {},
   "source": [
    "## AFTER — improved summary (extracted)\n",
    "In REAL mode you can parse the revised paragraph; in MOCK we’ll just pull it from the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple extraction of the revised paragraph after the marker \"REVISED SUMMARY:\"\n",
    "m = re.search(r\"REVISED SUMMARY:\\s*(.*)\", reflect_out, flags=re.DOTALL)\n",
    "after_summary = m.group(1).strip() if m else reflect_out.strip()\n",
    "print(after_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a45a5",
   "metadata": {},
   "source": [
    "✅ **What to copy into write-up document for Exercise 3**\n",
    "- Tools: Colab, OpenAI API (optional)\n",
    "- BEFORE summary\n",
    "- Self-critique prompt with criteria\n",
    "- AFTER revised summary\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Exercise_3_Self_Reflection_Improve_Summary.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
